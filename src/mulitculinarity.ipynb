{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for multiculinarity to see if OLS is a good model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check for no multicollinearity, you can use the Variance Inflation Factor (VIF) which measures how much the variance of the estimated regression coefficients are increased because of collinearity. A VIF of 1 means that there is no correlation between the predictor variable and the other predictor variable, a VIF greater than 1 means that there is a correlation, and the greater the VIF, the stronger the correlation. VIF can be calculated by using the library 'statsmodels' in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('../used_data/cleaned-dataset.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif = pd.DataFrame()\n",
    "vif[\"VIF Factor\"] = [variance_inflation_factor(df.values, i) for i in range(df.shape[1])]\n",
    "vif[\"features\"] = df.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other methods to check for multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_industry = df[df['Has Industry']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# define the independent variables (x) and the dependent variable (y)\n",
    "x = df_industry[['Average Payout', 'Hall of Famers',\n",
    "       'Number People', 'Maximum Reword', 'annocument_count','Reward Range Average',\n",
    "       'Validation Within Hours', 'P1 Average', 'P2 Average', 'P3 Average',\n",
    "       'P4 Average', 'Is Private', 'Is Safe Harbor_Partial safe harbor',\n",
    "       'Is Safe Harbor_Safe harbor', 'Is Safe Harbor_Not Safe Harbor']]\n",
    "y = df_industry['Vulnearbilities Rewarded']\n",
    "\n",
    "\n",
    "# Splitting your data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "\n",
    "\n",
    "\n",
    "# instantiate the LinearRegression object\n",
    "reg = LinearRegression()\n",
    "\n",
    "# fit the linear regression model\n",
    "reg.fit(x_train, y_train)\n",
    "\n",
    "# print the coefficients of the independent variables\n",
    "print(reg.coef_)\n",
    "\n",
    "# print the intercept of the model\n",
    "print(reg.intercept_)\n",
    "\n",
    "coef = reg.coef_\n",
    "coef_abs = np.abs(coef)\n",
    "top_n = np.argsort(coef_abs)[-7:]\n",
    "\n",
    "# get the names of the independent variables that correspond to the top n coefficients\n",
    "top_n_features = x.columns[top_n]\n",
    "\n",
    "print(top_n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the test set results\n",
    "y_pred = reg.predict(x_test)\n",
    "\n",
    "# Evaluating the performance of the model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "print(\"Mean squared error:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"R-squared:\", r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "\n",
    "# define the independent variables (x) and the dependent variable (y)\n",
    "x = df_industry[['Average Payout', 'Hall of Famers',\n",
    "       'Number People', 'Maximum Reword', 'annocument_count','Reward Range Average',\n",
    "       'Validation Within Hours', 'P1 Average', 'P2 Average', 'P3 Average',\n",
    "       'P4 Average', 'Is Private', 'Is Safe Harbor_Partial safe harbor',\n",
    "       'Is Safe Harbor_Safe harbor', 'Is Safe Harbor_Not Safe Harbor']]\n",
    "y = df_industry['Vulnearbilities Rewarded']\n",
    "\n",
    "# Splitting your data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# instantiate the LinearRegression object\n",
    "reg = LinearRegression()\n",
    "\n",
    "# fit the linear regression model\n",
    "reg.fit(x_train, y_train)\n",
    "\n",
    "# Check for linearity\n",
    "for i in x.columns:\n",
    "    plt.scatter(x_train[i], y_train)\n",
    "    plt.xlabel(i)\n",
    "    plt.ylabel('y')\n",
    "    plt.show()\n",
    "\n",
    "# Normality of errors\n",
    "residuals = y_test - reg.predict(x_test)\n",
    "sm.qqplot(residuals)\n",
    "\n",
    "# Homoscedasticity\n",
    "for i in x.columns:\n",
    "    plt.scatter(reg.predict(x_test),residuals)\n",
    "    plt.xlabel\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d3ddb9a339dcfec66cb1d066e0234a99f8d679773fa71ee722ae52c5be71efea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
