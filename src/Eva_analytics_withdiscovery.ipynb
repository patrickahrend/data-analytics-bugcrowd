{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import seaborn as sns\n",
    "import io "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_old = pd.read_excel(r\"C:\\Users\\eva-k\\Documents\\Studium\\TUM\\Master MMT\\5. Semester\\Cybercrime\\data-analytics-bugcrowd\\data-octa\\bugcrowd_modified_24.12.xlsx\")\n",
    "df_new = pd.read_excel(r\"C:\\Users\\eva-k\\Documents\\Studium\\TUM\\Master MMT\\5. Semester\\Cybercrime\\data-analytics-bugcrowd\\used_data\\07.01withdiscovery.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reward Range                 object\n",
       "Link                         object\n",
       "Title                        object\n",
       "Short Description            object\n",
       "Is Safe Harbor               object\n",
       "Vulnearbilities Rewarded    float64\n",
       "Validation Within            object\n",
       "Average Payout               object\n",
       "Hall of Famers               object\n",
       "Number People                object\n",
       "P4                           object\n",
       "P3                           object\n",
       "P2                           object\n",
       "P1                           object\n",
       "Maximum Reword               object\n",
       "programm_ruels               object\n",
       "annocument_count            float64\n",
       "Featured                     object\n",
       "Industry                     object\n",
       "Technology                   object\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Reward Range', 'Link', 'Title', 'Short Description', 'Is Safe Harbor',\n",
       "       'Vulnearbilities Rewarded', 'Validation Within', 'Average Payout',\n",
       "       'Hall of Famers', 'Number People', 'P4', 'P3', 'P2', 'P1',\n",
       "       'Maximum Reword', 'programm_ruels', 'annocument_count', 'Featured',\n",
       "       'Industry', 'Technology'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - 2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eva-k\\AppData\\Local\\Temp\\ipykernel_29600\\2001661482.py:1: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df_new['Reward Range'] = df_new['Reward Range'].str.replace('$', '').str.replace('Points', '0').str.replace(\",\", \"\")\n"
     ]
    }
   ],
   "source": [
    "#clean reward range\n",
    "df_new['Reward Range'] = df_new['Reward Range'].str.replace('$', '').str.replace('Points', '0').str.replace(\",\", \"\")\n",
    "df_new['Reward Range'] = df_new['Reward Range'].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SH:  143\n",
      "PSH:  76\n",
      "No:  111\n",
      "Safe harbor            143\n",
      "NaN                    111\n",
      "Partial safe harbor     76\n",
      "Name: Is Safe Harbor, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#count safe harbor\n",
    "\n",
    "partial_sh = (df_new['Is Safe Harbor'].value_counts()['Partial safe harbor'])\n",
    "\n",
    "sh = df_new['Is Safe Harbor'].value_counts()['Safe harbor']\n",
    "print(\"SH: \", sh)\n",
    "print(\"PSH: \", partial_sh)\n",
    "\n",
    "l = len(df_new['Is Safe Harbor'])\n",
    "no_sh= l - sh - partial_sh\n",
    "print(\"No: \", no_sh)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N/A\n",
      "96.0\n",
      "192.0\n",
      "N/A\n",
      "96.0\n",
      "N/A\n",
      "72.0\n",
      "360.0\n",
      "96.0\n",
      "N/A\n",
      "21.0\n",
      "N/A\n",
      "456.0\n",
      "72.0\n",
      "N/A\n",
      "72.0\n",
      "72.0\n",
      "240.0\n",
      "N/A\n",
      "240.0\n",
      "432.0\n",
      "N/A\n",
      "N/A\n",
      "N/A\n",
      "96.0\n",
      "N/A\n",
      "216.0\n",
      "N/A\n",
      "48.0\n",
      "N/A\n",
      "72.0\n",
      "72.0\n",
      "288.0\n",
      "72.0\n",
      "48.0\n",
      "96.0\n",
      "72.0\n",
      "13.0\n",
      "N/A\n",
      "72.0\n",
      "N/A\n",
      "N/A\n",
      "120.0\n",
      "648.0\n",
      "48.0\n",
      "168.0\n",
      "72.0\n",
      "72.0\n",
      "96.0\n",
      "N/A\n",
      "72.0\n",
      "360.0\n",
      "96.0\n",
      "N/A\n",
      "N/A\n",
      "N/A\n",
      "N/A\n",
      "96.0\n",
      "120.0\n",
      "72.0\n",
      "72.0\n",
      "N/A\n",
      "N/A\n",
      "N/A\n",
      "120.0\n",
      "48.0\n",
      "1440.0\n",
      "12.0\n",
      "96.0\n",
      "168.0\n",
      "48.0\n",
      "72.0\n",
      "168.0\n",
      "1440.0\n",
      "96.0\n",
      "72.0\n",
      "N/A\n",
      "168.0\n",
      "N/A\n",
      "96.0\n",
      "192.0\n",
      "N/A\n",
      "168.0\n",
      "N/A\n",
      "N/A\n",
      "N/A\n",
      "N/A\n",
      "N/A\n",
      "48.0\n",
      "2.0\n",
      "N/A\n",
      "N/A\n",
      "72.0\n",
      "72.0\n",
      "48.0\n",
      "288.0\n",
      "72.0\n",
      "7.0\n",
      "N/A\n",
      "48.0\n",
      "N/A\n",
      "N/A\n",
      "N/A\n",
      "96.0\n",
      "N/A\n",
      "48.0\n",
      "N/A\n",
      "N/A\n",
      "N/A\n",
      "192.0\n",
      "48.0\n",
      "N/A\n",
      "N/A\n",
      "48.0\n",
      "48.0\n",
      "72.0\n",
      "N/A\n",
      "72.0\n",
      "48.0\n",
      "N/A\n",
      "N/A\n",
      "96.0\n",
      "48.0\n",
      "N/A\n",
      "48.0\n",
      "48.0\n",
      "48.0\n",
      "192.0\n",
      "72.0\n",
      "48.0\n",
      "N/A\n",
      "120.0\n",
      "48.0\n",
      "144.0\n",
      "N/A\n",
      "72.0\n",
      "48.0\n",
      "264.0\n",
      "N/A\n",
      "96.0\n",
      "N/A\n",
      "N/A\n",
      "96.0\n",
      "72.0\n",
      "72.0\n",
      "72.0\n",
      "N/A\n",
      "N/A\n",
      "120.0\n",
      "120.0\n",
      "N/A\n",
      "48.0\n",
      "96.0\n",
      "N/A\n",
      "72.0\n",
      "N/A\n",
      "96.0\n",
      "13.0\n",
      "96.0\n",
      "N/A\n",
      "144.0\n",
      "120.0\n",
      "72.0\n",
      "N/A\n",
      "96.0\n",
      "216.0\n",
      "672.0\n",
      "N/A\n",
      "48.0\n",
      "N/A\n",
      "96.0\n",
      "6.0\n",
      "48.0\n",
      "48.0\n",
      "72.0\n",
      "72.0\n",
      "288.0\n",
      "N/A\n",
      "N/A\n",
      "432.0\n",
      "23.0\n",
      "13.0\n",
      "N/A\n",
      "N/A\n",
      "72.0\n",
      "N/A\n",
      "N/A\n",
      "N/A\n",
      "N/A\n",
      "13.0\n",
      "48.0\n",
      "72.0\n",
      "72.0\n",
      "48.0\n",
      "144.0\n",
      "N/A\n",
      "48.0\n",
      "456.0\n",
      "48.0\n",
      "72.0\n",
      "96.0\n",
      "N/A\n",
      "48.0\n",
      "48.0\n",
      "N/A\n",
      "48.0\n",
      "N/A\n",
      "N/A\n",
      "N/A\n",
      "N/A\n",
      "N/A\n",
      "N/A\n",
      "408.0\n",
      "72.0\n",
      "120.0\n",
      "N/A\n",
      "96.0\n",
      "48.0\n",
      "20.0\n",
      "N/A\n",
      "11.0\n",
      "96.0\n",
      "48.0\n",
      "96.0\n",
      "120.0\n",
      "96.0\n",
      "96.0\n",
      "48.0\n",
      "96.0\n",
      "72.0\n",
      "120.0\n",
      "96.0\n",
      "48.0\n",
      "N/A\n",
      "23.0\n",
      "96.0\n",
      "48.0\n",
      "48.0\n",
      "144.0\n",
      "N/A\n",
      "N/A\n",
      "N/A\n",
      "72.0\n",
      "72.0\n",
      "48.0\n",
      "1440.0\n",
      "72.0\n",
      "N/A\n",
      "N/A\n",
      "96.0\n",
      "96.0\n",
      "192.0\n",
      "N/A\n",
      "72.0\n",
      "72.0\n",
      "96.0\n",
      "N/A\n",
      "N/A\n",
      "144.0\n",
      "9.0\n",
      "144.0\n",
      "240.0\n",
      "48.0\n",
      "N/A\n",
      "4.0\n",
      "48.0\n",
      "120.0\n",
      "48.0\n",
      "48.0\n",
      "16.0\n",
      "N/A\n",
      "120.0\n",
      "168.0\n",
      "N/A\n",
      "72.0\n",
      "N/A\n",
      "72.0\n",
      "N/A\n",
      "48.0\n",
      "216.0\n",
      "144.0\n",
      "23.0\n",
      "N/A\n",
      "N/A\n",
      "N/A\n",
      "120.0\n",
      "72.0\n",
      "168.0\n",
      "N/A\n",
      "48.0\n",
      "N/A\n",
      "N/A\n",
      "48.0\n",
      "19.0\n",
      "48.0\n",
      "N/A\n",
      "22.0\n",
      "N/A\n",
      "192.0\n",
      "72.0\n",
      "1440.0\n",
      "96.0\n",
      "72.0\n",
      "N/A\n",
      "N/A\n",
      "N/A\n",
      "96.0\n",
      "72.0\n",
      "144.0\n",
      "96.0\n",
      "N/A\n",
      "120.0\n",
      "96.0\n",
      "96.0\n",
      "N/A\n",
      "72.0\n",
      "120.0\n",
      "96.0\n",
      "48.0\n",
      "21.0\n",
      "13.0\n",
      "N/A\n",
      "288.0\n",
      "144.0\n",
      "96.0\n",
      "N/A\n",
      "N/A\n",
      "N/A\n",
      "N/A\n",
      "N/A\n"
     ]
    }
   ],
   "source": [
    "#clean validation within\n",
    "\n",
    "# Apply the to_hours() function to the \"Validation Within\" column\n",
    "df_new[\"Validation Within\"].apply(lambda x: str(x))\n",
    "df_new[\"Validation Within\"] = df_new[\"Validation Within\"].fillna(value=\"N/A\")\n",
    "df_new[\"Validation Within\"].apply(lambda x: str(x))\n",
    "\n",
    "for i in df_new[\"Validation Within\"]:\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "to_hours() got an unexpected keyword argument 'result_type'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 47\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid unit: \u001b[39m\u001b[39m{\u001b[39;00munit\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     43\u001b[0m     \u001b[39mreturn\u001b[39;00m value\n\u001b[1;32m---> 47\u001b[0m df_new[\u001b[39m'\u001b[39m\u001b[39mValidation Within\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df_new[\u001b[39m'\u001b[39;49m\u001b[39mValidation Within\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(to_hours, result_type \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mbroadcast\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4661\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[0;32m   4662\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4666\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   4667\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m   4668\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4669\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4670\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4769\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4770\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4771\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\apply.py:1105\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1102\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[0;32m   1104\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1105\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\apply.py:1156\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1154\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1155\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[1;32m-> 1156\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[0;32m   1157\u001b[0m             values,\n\u001b[0;32m   1158\u001b[0m             f,\n\u001b[0;32m   1159\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[0;32m   1160\u001b[0m         )\n\u001b[0;32m   1162\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1163\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1164\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1165\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\_libs\\lib.pyx:2918\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\apply.py:139\u001b[0m, in \u001b[0;36mApply.__init__.<locals>.f\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mf\u001b[39m(x):\n\u001b[1;32m--> 139\u001b[0m     \u001b[39mreturn\u001b[39;00m func(x, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;31mTypeError\u001b[0m: to_hours() got an unexpected keyword argument 'result_type'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from datetime import timedelta\n",
    "\n",
    "def to_hours(s):\n",
    "    if pd.isnull(s):\n",
    "        # If the input is NaN, return NaN\n",
    "        return pd.np.nan\n",
    "    elif s == \"\":\n",
    "        return pd.np.nan\n",
    "    else:\n",
    "        # Extract the numerical value and the unit of time from the string\n",
    "        m = re.match(r'(\\d+) (days|hours|weeks|months)', s)\n",
    "        if not m:\n",
    "            # If the input is not in the expected format, check if it starts with \"about\"\n",
    "            if s.startswith(\"about \"):\n",
    "                # If it does, remove the \"about\" prefix and try again\n",
    "                s = s[6:]\n",
    "                m = re.match(r'(\\d+) (days|hours|weeks|months)', s)\n",
    "            \n",
    "            if not m:\n",
    "                print(f\"Error: Invalid input: {s}\")\n",
    "                return pd.np.nan\n",
    "        value, unit = m.groups()\n",
    "\n",
    "        # Convert the value to a float and the unit to lowercase\n",
    "        value = float(value)\n",
    "        unit = unit.lower()\n",
    "\n",
    "        # Convert the value to hours\n",
    "        if unit == 'days':\n",
    "            value *= 24\n",
    "        elif unit == 'hours':\n",
    "            pass\n",
    "        elif unit == 'weeks':\n",
    "            value *= 7 * 24\n",
    "        elif unit == 'months':\n",
    "            # Estimate the number of hours in a month based on 30 days\n",
    "            value *= 30 * 24\n",
    "        else:\n",
    "            print(f\"Error: Invalid unit: {unit}\")\n",
    "            raise ValueError(f\"Invalid unit: {unit}\")\n",
    "    \n",
    "    return value\n",
    "\n",
    "\n",
    "\n",
    "df_new['Validation Within'] = df_new['Validation Within'].apply(to_hours, result_type = 'broadcast')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df_new[\"Validation Within\"]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eva-k\\AppData\\Local\\Temp\\ipykernel_29600\\39423583.py:2: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df_new[\"Average Payout\"] = df_new[\"Average Payout\"].str.replace('$', '').str.replace(\",\",\"\")\n"
     ]
    }
   ],
   "source": [
    "#clean avareage payout \n",
    "df_new[\"Average Payout\"] = df_new[\"Average Payout\"].str.replace('$', '').str.replace(\",\",\"\")\n",
    "df_new[\"Average Payout\"] = df_new[\"Average Payout\"].fillna(\"0\")\n",
    "df_new[\"Average Payout\"] = df_new[\"Average Payout\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean number of people\n",
    "df_new[\"Number People\"]= df_new[\"Number People\"].str.replace(\"total\",\"\")\n",
    "df_new[\"Number People\"]= df_new[\"Number People\"].fillna(\"0\")\n",
    "df_new[\"Number People\"]= df_new[\"Number People\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean Hall of fame\n",
    "df_new[\"Hall of Famers\"] = df_new[\"Hall of Famers\"].fillna(\"0\")\n",
    "df_new[\"Hall of Famers\"] = df_new[\"Hall of Famers\"].str.replace(\"View all \",\"\").str.replace(\"View the hall\",\"0\")\n",
    "df_new[\"Hall of Famers\"] = df_new[\"Hall of Famers\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eva-k\\AppData\\Local\\Temp\\ipykernel_29600\\2083858369.py:4: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  row = row.str.replace(\"$\",\"\")\n"
     ]
    }
   ],
   "source": [
    "#Clean Priority Payout\n",
    "def cleanse_priority(row):\n",
    "    row = row.fillna(\"0\")\n",
    "    row = row.str.replace(\"$\",\"\")\n",
    "    return row \n",
    "\n",
    "df_new[\"P1\"] = cleanse_priority(df_new[\"P1\"])\n",
    "df_new[\"P2\"] = cleanse_priority(df_new[\"P2\"])\n",
    "df_new[\"P3\"] = cleanse_priority(df_new[\"P3\"])\n",
    "df_new[\"P4\"] = cleanse_priority(df_new[\"P4\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4decf9792df98ed63ccf7e956361b2d905b7b385ee952cd669d56c59d3f6bf63"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
